{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "alpha:  0.0002\n",
      "max iterations:  300\n",
      "min error for convergence:  0.1\n",
      "Reached convergence after  69  iterations\n",
      "Theta0:  -2.4767312712172263e-16\n",
      "Theta1:  -0.19220184130658569\n",
      "Theta2:  -0.1993422803512905\n",
      "Theta3:  -0.19287951780267984\n",
      "Theta4:  -0.20616830627827387\n",
      "Theta5:  0.1041793780877697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_rows', 500)\n",
    "%matplotlib inline\n",
    "%autosave 180\n",
    "\n",
    "# Declare column names for all variables, dependent variable, and independant variables\n",
    "cols = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "yCols = 'mpg'\n",
    "xCols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "\n",
    "# In order for the import statement to work correctly, the last three rows of the training set (the ones\n",
    "# with \"?\" instead of mpg, must be removed from the text file, this has already been done with the text file\n",
    "# provided in the zip\n",
    "data = pd.DataFrame(pd.read_csv('linear_regression_data.txt', header=None, names=cols, delim_whitespace=True))\n",
    "\n",
    "# Add testing samples\n",
    "samples = pd.DataFrame({\n",
    "    'cylinders': [4, 6, 4],\n",
    "    'displacement': [95, 168, 98],\n",
    "    'horsepower': [92, 96, 68],\n",
    "    'weight': [2043, 2981, 2147],\n",
    "    'acceleration': [19.1, 14.7, 18.3]\n",
    "})\n",
    "    \n",
    "# Standardize training set and testing samples\n",
    "sData = (data - data.mean()) / data.std()\n",
    "sSam = (samples - data[xCols].mean())/ data[xCols].std()\n",
    "\n",
    "# Assign dependent and independent variables\n",
    "y = sData[yCols]\n",
    "X = sData[xCols]\n",
    "\n",
    "# Add column of ones to dependent variable to hold value for y intercept\n",
    "ones = np.ones([X.shape[0],1])\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "\n",
    "# Create array of six values for theta and gradient (intercept, x1, x2, x3, x4, x5), initialize to zero\n",
    "theta = np.zeros([1,6])\n",
    "grad = np.zeros([6,1])\n",
    "\n",
    "# Linear regression cost function\n",
    "def costFunc(theta, X, y):\n",
    "    cost = 0\n",
    "    for m in range (len(X)):\n",
    "        hTheta = X[m].dot(theta.T)\n",
    "        cost += (1/2)*(np.square(hTheta-y[m]))\n",
    "        \n",
    "    return cost\n",
    "\n",
    "# Derivitive of cost function, used in gradient descent\n",
    "def costDerivitive(theta, grad, X, y):\n",
    "    for m in range(len(X)):\n",
    "        for n in range(len(grad)):\n",
    "            grad[n] += (theta[0][n] - y[m])*X[m][n]\n",
    "    return grad\n",
    "\n",
    "# Value of alpha, number of iterations, and error        \n",
    "alpha = 0.0002\n",
    "iterations = 300\n",
    "er = 0.1\n",
    "print(\"alpha: \", alpha)\n",
    "print(\"max iterations: \", iterations)\n",
    "print(\"min error for convergence: \", er)\n",
    "\n",
    "# Gradient descent function, iterates until delta(J) is less than error value, \n",
    "# max iterations are reached, or if J becomes too big\n",
    "# Returns cost and theta values\n",
    "def gradDescent(X, y, theta, alpha, iterations, er):\n",
    "    cost = np.zeros(iterations)\n",
    "    grad = np.zeros([6,1])\n",
    "    m = len(X)\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    J = costFunc(theta, X, y)\n",
    "\n",
    "    while not converged:\n",
    "        grad = costDerivitive(theta, grad, X, y)\n",
    "        \n",
    "        for n in range(len(grad)):\n",
    "            theta[0][n] = theta[0][n] - (1/2/m) * alpha * grad[n]\n",
    "        cost[iter] = costFunc(theta, X, y)\n",
    "        if(abs(J-cost[iter]) <= er):\n",
    "            print(\"Reached convergence after \", iter, \" iterations\")\n",
    "            converged = True\n",
    "            \n",
    "        J = cost[iter]\n",
    "        iter += 1\n",
    "        \n",
    "        if(iter == iterations):\n",
    "            print(\"max iterations reached\")\n",
    "            converged = True\n",
    "        if(J > 1000):\n",
    "            print(\"Cost is getting too big\")\n",
    "            converged = True\n",
    "            \n",
    "    return cost, theta\n",
    "\n",
    "# Call gradient descent function\n",
    "cost, theta = gradDescent(X, y, theta, alpha, iterations,er)\n",
    "\n",
    "# Assign values of theta array to their linear regression values and print\n",
    "theta0 = theta[0][0]\n",
    "theta1 = theta[0][1]\n",
    "theta2 = theta[0][2]\n",
    "theta3 = theta[0][3]\n",
    "theta4 = theta[0][4]\n",
    "theta5 = theta[0][5]\n",
    "\n",
    "print(\"Theta0: \", theta0)\n",
    "print(\"Theta1: \", theta1)\n",
    "print(\"Theta2: \", theta2)\n",
    "print(\"Theta3: \", theta3)\n",
    "print(\"Theta4: \", theta4)\n",
    "print(\"Theta5: \", theta5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         mpg  cylinders  displacement  horsepower  weight  acceleration\n",
       " 0  29.561168        4.0          95.0        92.0  2043.0          19.1,\n",
       "          mpg  cylinders  displacement  horsepower  weight  acceleration\n",
       " 0  23.462537        6.0         168.0        96.0  2981.0          14.7,\n",
       "          mpg  cylinders  displacement  horsepower  weight  acceleration\n",
       " 0  30.026994        4.0          98.0        68.0  2147.0          18.3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create array to hold predicted values\n",
    "samplePredictions = []\n",
    "\n",
    "# Assign test sample values to corresponding x variables and plug into regression equation\n",
    "for i in range(len(samples)):\n",
    "    x1 = sSam.iloc[i]['cylinders']\n",
    "    x2 = sSam.iloc[i]['displacement']\n",
    "    x3 = sSam.iloc[i]['horsepower']\n",
    "    x4 = sSam.iloc[i]['weight']\n",
    "    x5 = sSam.iloc[i]['acceleration']\n",
    "    stdMpg = theta0 + (x1*theta1) + (x2*theta2) + (x3 * theta3) + (x4 * theta4) + (x5 * theta5)\n",
    "    ans = pd.DataFrame({\n",
    "        'mpg': stdMpg,\n",
    "        'cylinders': x1,\n",
    "        'displacement': x2,\n",
    "        'horsepower': x3,\n",
    "        'weight': [x4],\n",
    "        'acceleration': [x5]\n",
    "    })\n",
    "    tmp = ans * data.std() + data.mean()\n",
    "    samplePredictions.append(tmp)\n",
    "# Print predicted mpg with accompyning independent variables\n",
    "samplePredictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
